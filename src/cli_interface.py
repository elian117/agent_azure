import sys
import signal
import time
import logging
from memory_system import MemorySystem
from azure_client import AzureOpenAIClient
from config import ConfigManager, LOG_FILE, LOG_FORMAT, LOG_LEVEL

# Configurar logging
logging.basicConfig(
    level=getattr(logging, LOG_LEVEL),
    format=LOG_FORMAT,
    handlers=[
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)


class AdvancedConversationalAgent:
    def __init__(self):
        self.memory = MemorySystem()
        self.azure_client = AzureOpenAIClient()
        self.running = True
        
        # Configurar manejo de se√±ales
        signal.signal(signal.SIGINT, self.signal_handler)
        
        logger.info("Agente conversacional avanzado inicializado")
    
    def signal_handler(self, sig, frame):
        """Manejar Ctrl+C elegantemente"""
        print("\n\nCerrando sesi√≥n...")
        self.show_session_summary()
        print("¬°Hasta luego!")
        logger.info("Sesi√≥n terminada por usuario")
        sys.exit(0)
    
    def show_welcome_message(self):
        """Mensaje de bienvenida avanzado"""
        print("=" * 80)
        print("AGENTE CONVERSACIONAL - AZURE OPENAI")
        print("=" * 80)
        print("¬°Bienvenido! Este es tu asistente conversacional con caracter√≠sticas avanzadas:")
        print("")
        print("Caracter√≠sticas:")
        print("  ‚Ä¢ Memoria inteligente con b√∫squeda por relevancia")
        print("  ‚Ä¢ Respuestas en streaming (tiempo real)")
        print("  ‚Ä¢ Configuraci√≥n externa personalizable")
        print("  ‚Ä¢ M√©tricas y logging detallado")
        print("  ‚Ä¢ Res√∫menes autom√°ticos de conversaciones")
        print("")
        print("Comandos disponibles:")
        print("  ‚Ä¢ 'exit' / 'quit'      ‚Üí Salir con resumen de sesi√≥n")
        print("  ‚Ä¢ 'clear'              ‚Üí Limpiar memoria de corto plazo")
        print("  ‚Ä¢ 'history'            ‚Üí Mostrar historial reciente")
        print("  ‚Ä¢ 'config'             ‚Üí Mostrar/editar configuraci√≥n")
        print("  ‚Ä¢ 'metrics'            ‚Üí Ver m√©tricas de uso")
        print("  ‚Ä¢ 'info'               ‚Üí Informaci√≥n del sistema")
        print("  ‚Ä¢ 'help'               ‚Üí Mostrar esta ayuda")
        print("")
        print("=" * 80)
    
    def show_streaming_indicator(self, show: bool = True):
        """Mostrar/ocultar indicador de streaming"""
        if show:
            print("Asistente: ", end="", flush=True)
        else:
            print()  # Nueva l√≠nea al terminar
    
    def process_special_command(self, user_input: str):
        """Procesar comandos especiales avanzados"""
        parts = user_input.strip().split(maxsplit=1)
        command = parts[0].lower()
        args = parts[1] if len(parts) > 1 else ""
        
        if command in ['exit', 'quit']:
            print("\nCerrando sesi√≥n...")
            self.show_session_summary()
            print("¬°Gracias por usar el agente conversacional!")
            return True
        
        elif command == 'clear':
            self.memory.clear_short_term()
            return "COMMAND_PROCESSED"
        
        elif command == 'history':
            limit = 10
            if args and args.isdigit():
                limit = int(args)
            self.memory.show_recent_history(limit)
            return "COMMAND_PROCESSED"
        
        elif command == 'config':
            if not args:
                self.show_config_menu()
            else:
                self.handle_config_command(args)
            return "COMMAND_PROCESSED"
        
        elif command == 'metrics':
            self.show_metrics_dashboard()
            return "COMMAND_PROCESSED"
        
        elif command == 'info':
            self.show_system_info()
            return "COMMAND_PROCESSED"
        
        elif command == 'help':
            self.show_welcome_message()
            return "COMMAND_PROCESSED"
        
        return False
    
    def show_config_menu(self):
        """Mostrar men√∫ de configuraci√≥n"""
        config_summary = ConfigManager.get_config_summary()
        model_config = ConfigManager.load_model_config()
        
        print("\nCONFIGURACI√ìN ACTUAL")
        print("=" * 50)
        print(f"System Prompt: {config_summary['system_prompt_length']} caracteres")
        print(f"Archivo: {config_summary['system_prompt_file']}")
        print()
        print("Par√°metros del Modelo:")
        for key, value in model_config.items():
            print(f"   ‚Ä¢ {key}: {value}")
        print()
        print("Sistema:")
        print(f"   ‚Ä¢ M√©tricas: {'‚úÖ' if config_summary['metrics_enabled'] else '‚ùå'}")
        print(f"   ‚Ä¢ Logging: {'‚úÖ' if config_summary['logging_enabled'] else '‚ùå'}")
        print(f"   ‚Ä¢ Log file: {config_summary['log_file']}")
        print()
        print("Comandos de configuraci√≥n:")
        print("  ‚Ä¢ 'config temp 0.8'     ‚Üí Cambiar temperatura")
        print("  ‚Ä¢ 'config tokens 2000'  ‚Üí Cambiar max_tokens")
        print("  ‚Ä¢ 'config stream on'    ‚Üí Activar streaming")
        print("  ‚Ä¢ 'config stream off'   ‚Üí Desactivar streaming")
        print("=" * 50)
    
    def handle_config_command(self, args: str):
        """Manejar comandos de configuraci√≥n"""
        parts = args.split()
        if len(parts) < 2:
            print("Formato incorrecto. Ejemplo: config temp 0.8")
            return
        
        param = parts[0].lower()
        value = parts[1]
        
        try:
            if param in ['temp', 'temperature']:
                success = self.azure_client.update_model_config(temperature=float(value))
            elif param in ['tokens', 'max_tokens']:
                success = self.azure_client.update_model_config(max_tokens=int(value))
            elif param == 'stream':
                stream_val = value.lower() in ['on', 'true', '1', 'yes']
                success = self.azure_client.update_model_config(stream=stream_val)
            elif param == 'top_p':
                success = self.azure_client.update_model_config(top_p=float(value))
            else:
                print(f"Par√°metro desconocido: {param}")
                return
            
            if success:
                print(f"Configuraci√≥n actualizada: {param} = {value}")
            else:
                print(f"Error actualizando configuraci√≥n")
                
        except ValueError as e:
            print(f"Valor inv√°lido: {e}")
    
    def show_metrics_dashboard(self):
        """Mostrar dashboard de m√©tricas"""
        stats = self.azure_client.get_usage_stats()
        memory_stats = self.memory.get_memory_stats()
        
        print("\nM√âTRICAS")
        print("=" * 60)
        
        print("Sesi√≥n Actual:")
        current = stats.get('current_session', {})
        duration = current.get('session_duration', 0)
        hours = int(duration // 3600)
        minutes = int((duration % 3600) // 60)
        
        print(f"   ‚Ä¢ Duraci√≥n: {hours}h {minutes}m")
        print(f"   ‚Ä¢ Interacciones: {current.get('interactions', 0)}")
        print(f"   ‚Ä¢ Tokens usados: {current.get('total_tokens', 0):,}")
        print(f"   ‚Ä¢ Tiempo promedio de respuesta: {current.get('average_response_time', 0):.2f}s")
        print(f"   ‚Ä¢ Errores: {sum(current.get('errors', {}).values())}")
        
        print("\nEstad√≠sticas Globales:")
        print(f"   ‚Ä¢ Total sesiones: {stats.get('total_sessions', 0)}")
        print(f"   ‚Ä¢ Total interacciones: {stats.get('total_interactions', 0)}")
        print(f"   ‚Ä¢ Total tokens: {stats.get('total_tokens_used', 0):,}")
        print(f"   ‚Ä¢ Interacciones recientes (7d): {stats.get('recent_interactions_7d', 0)}")
        
        print("\nMemoria:")
        print(f"   ‚Ä¢ Conversaciones totales: {memory_stats.get('total_conversations', 0)}")
        print(f"   ‚Ä¢ Conversaciones activas: {memory_stats.get('active_conversations', 0)}")
        print(f"   ‚Ä¢ Tokens en memoria: {memory_stats.get('total_tokens', 0):,}")
        print(f"   ‚Ä¢ Res√∫menes: {memory_stats.get('summaries_count', 0)}")
        print(f"   ‚Ä¢ Tama√±o archivo memoria: {memory_stats.get('memory_file_size', 0) / 1024:.1f} KB")
        print("=" * 60)
    
    def show_system_info(self):
        """Mostrar informaci√≥n del sistema"""
        model_info = self.azure_client.get_model_info()
        config_summary = ConfigManager.get_config_summary()
        
        print("\nüíª INFORMACI√ìN DEL SISTEMA")
        print("=" * 60)
        
        print("Azure OpenAI:")
        print(f"   ‚Ä¢ Endpoint: {model_info.get('endpoint', 'N/A')}")
        print(f"   ‚Ä¢ Deployment: {model_info.get('deployment', 'N/A')}")
        print(f"   ‚Ä¢ API Version: {model_info.get('api_version', 'N/A')}")
        print(f"   ‚Ä¢ Streaming: {'‚úÖ' if model_info.get('streaming_enabled') else '‚ùå'}")
        
        print("\nConfiguraci√≥n:")
        print(f"   ‚Ä¢ System prompt: {model_info.get('system_prompt_length', 0)} caracteres")
        print(f"   ‚Ä¢ Temperatura: {model_info.get('model_config', {}).get('temperature', 'N/A')}")
        print(f"   ‚Ä¢ Max tokens: {model_info.get('model_config', {}).get('max_tokens', 'N/A')}")
        
        print(f"\nArchivos:")
        print(f"   ‚Ä¢ Config: {config_summary.get('model_config_file', 'N/A')}")
        print(f"   ‚Ä¢ Memoria: {config_summary.get('memory_file', 'N/A')}")
        print(f"   ‚Ä¢ Logs: {config_summary.get('log_file', 'N/A')}")
        
        print("=" * 60)
    
    def show_session_summary(self):
        """Mostrar resumen al finalizar sesi√≥n"""
        stats = self.azure_client.get_usage_stats()
        current = stats.get('current_session', {})
        
        duration = current.get('session_duration', 0)
        hours = int(duration // 3600)
        minutes = int((duration % 3600) // 60)
        seconds = int(duration % 60)
        
        print("\nRESUMEN DE SESI√ìN")
        print("=" * 50)
        print(f"Duraci√≥n: {hours:02d}:{minutes:02d}:{seconds:02d}")
        print(f"Interacciones: {current.get('interactions', 0)}")
        print(f"Tokens usados: {current.get('total_tokens', 0):,}")
        if current.get('interactions', 0) > 0:
            print(f"Promedio por respuesta: {current.get('average_response_time', 0):.2f}s")
            print(f"Tokens promedio: {current.get('average_tokens_per_interaction', 0):.0f}")
        
        errors = sum(current.get('errors', {}).values())
        if errors > 0:
            print(f"Errores: {errors}")
        
        print("Todas las conversaciones han sido guardadas")
        print("=" * 50)
    
    def initialize(self):
        """Inicializar el agente avanzado"""
        self.show_welcome_message()
        
        # Probar conexi√≥n
        print("Probando conexi√≥n con Azure OpenAI...")
        if not self.azure_client.test_connection():
            print("No se pudo conectar con Azure OpenAI.")
            print("Verifica las credenciales en src/config.py")
            return False
        print("Conexi√≥n exitosa")
        
        # Mostrar informaci√≥n del modelo
        model_info = self.azure_client.get_model_info()
        print(f"Modelo: {model_info.get('deployment', 'N/A')}")
        print(f"Streaming: {'Activado' if model_info.get('streaming_enabled') else 'Desactivado'}")
        
        # Cargar memoria
        print("Cargando memoria de conversaciones...")
        self.memory.load_from_long_term()
        
        # Mostrar estad√≠sticas iniciales
        memory_stats = self.memory.get_memory_stats()
        if memory_stats.get('total_conversations', 0) > 0:
            print(f"Memoria: {memory_stats['total_conversations']} conversaciones, {memory_stats['total_tokens']:,} tokens")
        print("-" * 80)
        logger.info("Agente inicializado exitosamente")
        return True
    
    def run(self):
        """Bucle principal con streaming avanzado"""
        if not self.initialize():
            return
        
        while self.running:
            try:
                # Entrada del usuario
                user_input = input(f"\nüë§ T√∫: ").strip()
                
                if not user_input:
                    continue
                
                # Procesar comandos especiales
                command_result = self.process_special_command(user_input)
                if command_result == True:  # exit
                    break
                elif command_result == "COMMAND_PROCESSED":  # comando ejecutado
                    continue
                
                # Preparar contexto inteligente
                start_time = time.time()
                context_messages, context_sources = self.memory.get_intelligent_context(user_input)
                
                logger.info(f"Contexto preparado: {len(context_messages)} mensajes de {context_sources}")
                
                # Mostrar indicador de streaming
                self.show_streaming_indicator(True)
                
                # Generar respuesta con streaming
                full_response = ""
                metrics = {}
                
                response_generator = self.azure_client.generate_response_stream(
                    user_input, context_messages, context_sources
                )
                
                for chunk in response_generator:
                    if isinstance(chunk, str):
                        # Es un chunk de texto
                        print(chunk, end="", flush=True)
                        full_response += chunk
                    else:
                        # Es el resultado final con m√©tricas
                        metrics, complete_response = chunk
                        full_response = complete_response
                        break
                
                # Finalizar streaming
                self.show_streaming_indicator(False)
                
                # Mostrar m√©tricas si no hay errores
                if not metrics.get('error'):
                    response_time = metrics.get('response_time', 0)
                    tokens_used = metrics.get('total_tokens', 0)
                    print(f"{response_time:.1f}s | {tokens_used} tokens")
                    
                    # Guardar en memoria
                    self.memory.add_interaction(
                        user_input, 
                        full_response, 
                        metadata={
                            'response_time': response_time,
                            'tokens': tokens_used,
                            'context_sources': context_sources
                        }
                    )
                    
                    logger.info(f"Interacci√≥n completada: {tokens_used} tokens, {response_time:.2f}s")
                else:
                    # Manejar errores
                    error_type = metrics.get('error')
                    print(f"\n {full_response}")
                    
                    if error_type == 'context_length_error':
                        print("üí° Intenta usar 'clear' para reducir el contexto")
                    elif error_type == 'rate_limit_error':
                        print("‚è≥ Espera un momento antes del siguiente mensaje")
                
            except KeyboardInterrupt:
                break
            except EOFError:
                print("\n")
                self.show_session_summary()
                print("¬°Hasta luego!")
                break
            except Exception as e:
                print(f"\nError inesperado: {e}")
                logger.error(f"Error en bucle principal: {e}")
                print("Continuando...")


def main():
    """Funci√≥n principal avanzada"""
    print("INICIANDO AGENTE CONVERSACIONAL")
    print("=" * 50)
    
    # Verificar Python
    if sys.version_info < (3, 8):
        print("Requiere Python 3.8+")
        return
    
    print(f"Python: {sys.version.split()[0]}")
    
    # Verificar dependencias
    try:
        import openai
        print(f"OpenAI: {openai.__version__}")
    except ImportError:
        print("OpenAI no encontrado. Ejecuta: pip install openai")
        return
    
    # Crear y ejecutar agente
    agent = AdvancedConversationalAgent()
    
    try:
        agent.run()
    except KeyboardInterrupt:
        print("\n\nInterrumpido por usuario")
        agent.show_session_summary()
    except Exception as e:
        print(f"\nError cr√≠tico: {e}")
        logger.error(f"Error cr√≠tico: {e}")
    finally:
        logger.info("Sesi√≥n finalizada")


if __name__ == "__main__":
    main()